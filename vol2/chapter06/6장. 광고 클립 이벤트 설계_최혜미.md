# 6장. 광고 클릭 이벤트 설계

## 1. 문제 이해 및 설계 범위 확정

### 1.1. 핵심 배경
- **디지털 광고의 중요성**: 광고 클릭 이벤트 집계는 RTB(Real-Time Bidding) 시스템의 핵심 프로세스로, 광고 성과(CTR, CVR)에 직접적인 영향을 미친다.
- **요구사항**:
    - **기능**:
        - 지난 M분 동안 특정 ad_id에 대한 클릭 수 집계
        - 매 분마다 가장 많이 클릭된 상위 N개 광고(ad_id) 반환
        - ip, user_id, country 등 다양한 속성을 기준으로 필터링 지원
    - **비기능**:
        - 데이터 정확성 보장 (광고 과금 및 RTB에 사용)
        - 지연되거나 중복된 이벤트 처리
        - 견고한 시스템(부분 장애 감내)과 전체 처리 시간 최대 수 분 이내

### 1.2. 입력 데이터 및 규모 추정
- **입력 데이터 형식**:
    - 로그 파일 형태로 기록, 각 이벤트는 `ad_id, click_timestamp, user_id, ip, country` 정보를 포함
- **데이터 양**:
    - 매일 약 10억 건의 광고 클릭 이벤트
    - 광고 게재는 2백만 회 수준, 연간 30%씩 증가 추세
- **추정치**:
    - DAU: 10억 명 (각 사용자가 하루에 평균 1회 클릭)
    - 평균 QPS: 10,000 건, 최대 QPS: 평균의 5배 (약 50,000 건)
    - 광고 클릭 이벤트 하나당 약 0.1KB → 일일 저장 용량 약 100GB, 월간 약 3TB

## 2. 개략적 설계안 및 API 설계

### 2.1. 질의 API 설계

#### API 1: ad_id별 클릭 수 집계
- **엔드포인트**: `GET /v1/ads/{:ad_id}/aggregated_count`
- **Request Param**:
    - `from`: 집계 시작 시간 (long)
    - `to`: 집계 종료 시간 (long)
    - `filter`: 필터링 전략 식별자 (long)
- **Response Body**:
    - `ad_id`: 광고 식별자 (string)
    - `count`: 집계된 클릭 횟수 (long)

#### API 2: 가장 많이 클릭된 상위 N개 광고 반환
- **엔드포인트**: `GET /v1/ads/popular_ads`
- **Request Param**:
    - `count`: 상위 몇 개의 광고 반환 (integer)
    - `window`: 분 단위 집계 윈도 크기 (integer)
    - `filter`: 필터링 전략 식별자 (long)
- **Response Body**:
    - `ad_ids`: 광고 식별자 목록 (array)

### 2.2. 데이터 모델

#### A. 원시 데이터 (Raw Data)
- 예:  
  `AdClickEvent: ad001, 2021-01-01 00:00:01, user1, 207.148.22.22, USA`

#### B. 집계 결과 데이터
- 테이블 구조 예시:
    - `ad_id | click_minute | filter_id | count`
    - 필터별 집계:  
      예)
      ```
      filter_id: 0012  → US 관련 필터
      filter_id: 0023  → 특정 IP나 user_id 조건
      ```

#### 비교: 원시 데이터 보관 vs 집계 결과 데이터 보관
- **원시 데이터 보관**:
    - 장점: 원본 데이터 손실 없이 재계산 및 디버깅 지원
    - 단점: 막대한 데이터 용량, 낮은 질의 성능
- **집계 데이터 보관**:
    - 장점: 데이터 용량 절감, 빠른 질의 성능
    - 단점: 원시 데이터 손실 시 재계산 어려움
- **결론**: 둘 다 저장하는 것이 좋음
    - 원시 데이터는 백업 및 재계산 용도로, 집계 데이터는 실시간 질의를 위해 사용

## 3. 상세 설계

### 3.1. 비동기 처리 및 메시지 큐
- **전체 프로세스**:
    - 원시 이벤트 스트림은 카프카와 같은 메시지 큐를 통해 집계 서비스로 전달
    - **두 개의 메시지 큐** 사용:
        - 첫 번째 큐: 원시 광고 클릭 이벤트 기록
        - 두 번째 큐: 분 단위 집계 데이터 및 상위 광고 집계 결과 전송
- **정확하게 한 번 처리 (exactly-once)**:
    - 다운스트림에서 집계 결과 수신 확인 후 오프셋 저장

### 3.2. 집계 서비스 및 MapReduce 패러다임
- **맵 노드**:
    - 원시 데이터를 필터링 및 전처리 (예: ad_id % N 기반 분배)
- **집계 노드**:
    - 각 ad_id별 클릭 수를 매 분 집계 (메모리 내 집계)
- **리듀스 노드**:
    - 여러 집계 노드의 결과를 최종 축약, 예를 들어 상위 N개 광고 산출

#### 주요 사용 사례
- **사례 1**: 지난 M분 동안 ad_id 클릭 수 집계
- **사례 2**: 상위 N개 광고 반환 (예: 지난 1분간 가장 많이 클릭된 상위 100개 광고)
- **사례 3**: 특정 필터(예: 미국 내 광고)에 따른 집계 지원

### 3.3. 스트리밍 vs 일괄 처리 (Lambda/Kappa 아키텍처)
- **Lambda 아키텍처**:
    - 스트리밍(실시간)과 일괄(오프라인) 처리 경로를 모두 지원
    - 단점: 유지보수 코드 증가
- **Kappa 아키텍처**:
    - 단일 스트림 처리 경로로 통합하여 관리 복잡성을 낮춤

### 3.4. 집계 윈도 및 이벤트 지연 처리
- **윈도잉 전략**:
    - **텀블링 윈도**: 고정 간격으로 겹치지 않는 집계 (매 분 집계에 적합)
    - **슬라이딩 윈도**: 일정 구간 동안의 이벤트 집계 (M분간 상위 N개 광고 산출에 적합)
- **늦게 도착하는 이벤트 처리**:
    - **워터마크(Watermark) 기법**: 집계 윈도에 워터마크를 부여해 늦게 도착한 이벤트를 포함시킴
        - 워터마크 간격이 짧으면 응답성이 높으나 정확도 저하, 길면 정확도는 높으나 지연 증가

### 3.5. 전달 보장 및 결함 내성
- **전달 보장**:
    - ‘정확히 한 번(Exactly Once)’ 처리 방식을 권장하여 중복 처리 및 데이터 손실 방지
    - 다운스트림 수신 확인 후 오프셋 커밋
- **결함 내성 (Fault Tolerance)**:
    - 집계 서비스 노드 장애 시, 카프카 브로커에서 재처리
    - 시스템 상태(오프셋, 마지막 스냅샷 등)를 주기적으로 저장하여 복구 지원

## 4. 시스템 규모 확장 및 모니터링

### 4.1. 확장 전략
- **메시지 큐**:
    - 생산자 인스턴스 수에 제한 없고, 소비자 그룹 재조정을 통해 확장
    - 파티션 수 및 토픽 샤딩을 통한 대역폭 확장 (동일 ad_id 이벤트가 한 파티션에 저장되도록 해시 키 사용)
- **집계 서비스**:
    - 수평적 확장을 위해 노드 추가/삭제 가능 (ad_id별 별도 처리 스레드 할당)
- **데이터베이스**:
    - Cassandra와 같은 분산 DB를 활용하여 안정 해시 기반 수평 확장 지원

### 4.2. 핫스팟 문제 해결
- 특정 ad_id에 집중된 이벤트로 인한 과부하를 방지하기 위해:
    - 더 많은 집계 서비스 노드를 할당하거나 전역/지역 집계 방식 도입

### 4.3. 모니터링 및 조정
- **모니터링 포인트**:
    - 메시지 큐 크기, 처리 지연, 집계 노드의 CPU/메모리 사용량
    - 각 노드의 timestamp 차이로 지연 시간 측정
- **데이터 조정(Reconciliation)**:
    - 배치 작업으로 집계 결과와 실시간 결과 비교하여 데이터 무결성 보증

## 5. 대안적 설계안
- **하이브/ElasticSearch 기반**:
    - 원시 데이터를 하이브(Hive)에 저장하고, ElasticSearch 계층에서 빠른 질의를 수행
- **OLAP DB 활용**:
    - ClickHouse, Druid 등의 OLAP 데이터베이스를 통한 집계 처리

## 6. 결론 및 마무리
- **데이터 모델 및 API 설계**:
    - 원시 데이터와 집계 데이터 모두를 저장해 디버깅 및 빠른 질의를 지원
- **집계 처리**:
    - MapReduce 패러다임을 활용하여 분산 집계 처리
- **확장성 및 결함 내성**:
    - 메시지 큐, 집계 서비스, 데이터베이스를 독립적으로 확장하며 핫스팟 문제와 장애 복구를 고려
- **정확성 및 모니터링**:
    - 워터마크, 정확히 한 번 처리 보장, 지속적 모니터링 및 데이터 조정으로 데이터 무결성 보증


