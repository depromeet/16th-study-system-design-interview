# 6장 - key-value 저장소 설계
- key-value pair
    - key-value DB에 저장되는 값은 고유 식별자를 키로 가져야 함
- key는 유일해야함.
- value는 쌍이 되는 key를 통해서만 접근할 수 있다.
- key는 일반 텍스트일 수도 있고, 해시 값일 수도 있다.
- value는 문자열, 리스트, 객체 등이 될 수 있고, 보통 value에 어떤 것이 오든 상관하지 않는다.

## 문제 이해 및 설계 범위 확정
### 요구 사항
- key-value 쌍의 크기는 10KB 이하이다.
- 큰 데이터를 저장할 수 있어야 한다.
- 높은 가용성을 제공해야 한다.
    - 장애가 있어도 빠르게 응답해야함
- 높은 규모 확장성을 제공해야 한다.
    - 트래픽 양에 따라 자동적으로 서버 증설/삭제가 되어야 함.
- 데이터 일관성 수준을 조정할 수 있어야 한다.
- latency가 짧아야 함.

## 단일 서버 key-value 저장소
- key-value pair를 전부 메모리에 해시 테이블로 저장
    - 가장 직관적임.
    - 속도는 빠름
    - 모든 데이터를 메모리 안에 두는 것은 불가능함.
    - 개선책
        - 데이터 압축(compression)
        - 자주 쓰는 데이터만 메모리에 적재하고 나머지는 디스크에 저장

## qnstks key-value 저장소
### CAP 정리
- 세 가지 요구 사항
    - 데이터 일관성(consistency)
        - 분산 시스템에 접속하는 모든 클라이언트는 접속한 노드에 상관 없이 언제나 같은 데이터를 보게 됨
    - 가용성(availability)
        - 일부 노드에 장애가 발생해도 항상 응답을 받을 수 있어야함.
    - 파티션 감내(partition tolerance)
        - 파티션 감내는 네트워크에서 두 노드 사이에서 통신 장애가 발생해도 시스템은 계속 동작해야 함.
            - 파티션 : 두 노드 사이에 통신 장애가 발생
- 위 세 가지 요구 사항을 만족하는 분산 시스템은 불가능하다는 정리
- CP 시스템
    - 일관성과 파티션 감내를 지원하는 key-value 저장소
    - 가용성을 희생
- AP 시스템
    - 가용성과 파티션 감내를 지원하는 key-value 저장소
    - 데이터 일관성을 희생
- CA 시스템
    - 일관성과 가용성을 지원하는 key-value 저장소
    - 파티션 감내를 의생
    - 통상 네트워크 장애는 피할 수 없는 일로 여겨짐
    - 분산 시스템은 반드시 파티션 문제를 감내할 수 있어야 함.
    - CA 시스템은 실 세계에 존재하지 않음.

### 실세계의 분산 시스템
- 분산 시스템은 파티션 문제를 피할 수 없음.
- 따라서 일관성과 가용성 사이에서 하나를 선택해야 함.

### A, B, C 세 개의 서버 환경에서 C 서버에 장애 발생 시
- 일관성을 선택할 경우 (CP 시스템)
    - 불일치 문제를 해결하기 위해 장애가 발생하지 않은 A와 B에 대해서 쓰기 연산을 중단해야함.
        - 가용성이 깨지게 됨.
        - 은행권 시스템은 보통 데이터 일관성을 양보하지 않음.
- 가용성을 선택할 경우 (AP 시스템)
    - 낡은 데이터를 반환할 위험이 있더라도 계속 읽기 연산을 허용해야 함.
    - 장애가 발생하지 않은 A, B에 계속 쓰기 작업이 일어나고, 장애 해결 후 C에 새 데이터를 전송함.

### 데이터 파티션
- 데이터를 작은 파티션들로 분할하여 여러 서버에 저장
- 데이터 파티션 시 중요하게 다뤄야할 문제
    - 데이터를 여러 서버에 고르게 분산할 수 있는가
    - 노드가 추가되거나 삭제 시 데이터 이동을 최소화할 수 있는가
- 안정 해시를 사용하면 위의 문제를 풀기에 적합하다.
    - 규모 확장 자동화
        - 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제됨
    - 다양성
        - 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다.

### 데이터 다중화
- 높은 가용성과 안정성을 위해 데이터를 N 개의 서버에 비동기적으로 다중화할 필요가 있다.
- 가상 노드 선택 시 선택한 N개의 노드가 대응될 실제 물리 서버의 개수 N보다 작아질 수 있다.
    - 노드 선택 시 같은 물리 서버를 중복 선택하지 않도록 해야 함.
- 실제 같은 물리 서버에 저장되면 여전히 안정성에 문제가 생길 수 있음.
    - 안정성 확보를 위해 데이터 사본은 다른 센터의 서버에 저장하고, 고속 네트워크로 연결되어야 함.

### 데이터 일관성
- 여러 노드에 다중화된 데이터는 적절히 동기화 되어야 함.
- 정족수 합의(Quorum Consensus) 프로토콜을 사용하면 읽기/쓰기 연산 모두에서 일관성을 보장할 수 있다.
    - N : 사본 개수
    - W : 쓰기 연산에 대한 정족수, 쓰기 연산이 성공했다고 하기 위해서는 적어도 W 개의 서버에서 쓰기 연산 성공에 대한 응답을 받아야 함.
    - R : 읽기 연산에 대한 정족수, 읽기 연산이 성공한 것으로 간주되려면 적어도 R 개의 서버로부터 응답을 받아야 한다.
- 중재자(coordinator)는 클라이언트와 노드 사이 프록시 역할을 함.
- W + R > N
    - 강환 일관성이 보장됨
- R = 1 && W = N
    - 빠른 읽기 연산에 최적화된 시스템
- W = 1 && R = N
    - 빠른 쓰기 연산에 최적화된 시스템
- W + R > N
    - 강한 일관성이 보장됨 (보통 N = 3, W = R = 2)
- W + R <= N
    - 강한 일관성이 보장되지 않음

### 일관성 모델
- 강한 일관성
    - 모든 읽기 연산은 가장 최샌 결과를 반환
    - 클라이언트는 절대 낡은 데이터를 보지 못함
    - 모든 사본에 현재 쓰기 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지
    - 새로운 요청 처리가 중단되기에 고가용성이 떨어지게됨.
- 약한 일관성
    - 읽기 연산은 가장 최신 결과를 반환하지 못할 수 있음
- 최종 일관성
    - 다이나모와 카산드라 등이 채택함.
    - 약한 일관성의 한 형태
    - 갱신 결과가 결국에는 모든 사본에 반영(동기화)되는 모델
    - 쓰기 연산이 병렬저긍로 일어나면 시스템에 저장된 값의 일관성이 깨질 수 있음.
        - 이를 클라이언트가 해결해야 함.
        - 비 일관성 해소 기법 : 데이터 비저닝
            - 데이터 변경 시 마다 해당 데이터의 새로운 버전을 만듦
                - 각 버전의 데이터는 immutable임
            - 벡터 시계
                - 데이터에 [서버, 버전] pair를 매닮
                - 선행 버전과 후행 버전, 다른 버전과 충돌 판별에 사용됨
                - 어떤 버전 X가 버전 Y의 이전 버전인지 쉽게 판단할 수 있음.
                - 버전 Y에 포함된 모든 구성 요소의 값이 X에 포함된 모든 구성요소 값보다 같거나 큰지만 보면 됨.
                - 단점
                    - 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로 클라이언트 구현이 복잡해짐.
                    - [서버, 버전] pair가 굉장히 빠르게 늘어남.
                        - 어떤 임계치를 설정하고 임계치 이상 길어지면 오래된 순서쌍을 제거하도록 해야함.
                        - 하지만, 이렇게하면 버전 간 선후 관계가 정확하게 결정될 수 없어서 충돌 해소 과정의 효율성이 감소함.
                        - 아마존에서는 실제 서비스에서 이런 문제를 본 적은 없어서 괜찮을 것이라고 생각함.

### 장애 감지
- 분산 시스템에서는 한 대의 서버가 특정 서버가 죽었다고해서 바로 장애처리 하지 않고, 두 대 이상이 같은 장애를 보고해야 장애로 판단함.
- 모든 노드 사이에 멀티 캐스팅 채널을 구축하는 방법은 가장 쉽지만 비효율적임.
- gossip protocol 같은 분산형 장애 감지(decentralized failure detection) 솔루션을 선택하는 것이 효율적임.
- 가십 프로토콜
    - 각 노드는 멤버십 목록을 유지한다.
        - 멤버십 목록은 각 멤버 ID와 그 박동 카운터(heartbeat counter) 쌍의 목록임
    - 각 노드는 주기적으로 자신의 박동 카운터를 증가 시킴
    - 각 노드는 무작위로 선정된 노드에게 주기적으로 자신의 박동 카운터 목록을 보냄
    - 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신
    - 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버를 장애 상태로 간주함.

### Q) 모든 노드가 서로 직접 통신하는가...?

### 일시적인 장애 처리
- 네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버가 잠시 맡아 처리함.
    - 그 동안 발생한 변경 사항은 해당 서버가 복구되면 일관 반영해 데이터 일관성을 보존함.
    - 이를 위해서 임시로 쓰기 연산을 처리한 서버에는 이에 대한 hint를 남겨 둔다.
    - 이를 단서 후 임시 위탁(hinted handoff)라고 부른다.

### 영구 장애 처리
- 반-엔트로피(anti-entropy) 프로토콜을 구현해 사본들을 동기화
    - 반-엔트로피 프로토콜은 사본들을 비교해 최신 버전으로 갱신하는 과정을 포함함.
    - 사본 간의 일관성이 망가지 상태를 탐지하고 전송 데이터의 양을 줄이기 위해 머클(Merkle) 트리를 사용함.
        - 머클 트리는 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드딀의 레이블로부터 계산된 해시 값을 레이블로 붙여두는 트리임.
        - 1단계
            - 키 공간을 버킷으로 나눈다.
        - 2단계
            - 버킷에 포함된 각각의 키에 균등 분포 해시 함수를 적용해 해시 값을 계산함
        - 3단계
            - 버킷별로 해시값을 계산 후 해당 해시 값을 레이블로 갖는 노드를 만든다.
        - 4단계
            - 자식 노드의 레이블로부터 새로운 해시 값을 계산해, 이진 트리를 상향식으로 구성해 나간다.
        - 각 서버의 루트부터 이진 트리를 비교해 하향식으로 틀린 부분을 찾아나간다.
        - 동기화해야 하는 데이터의 양은 실제로 존재하는 차이의 크기에 비례할 뿐임.
        - 두 서버에 보관된 데이터의 총량과는 무관함.
        - 하지만, 실제 시스템의 경우 버킷 하나의 크기가 꽤 크다.

## 요약
- 대규모 데이터 저장
    - 안정 해시를 사용해 서버들에 부하 분산
- 읽기 연산에 대한 높은 가용성 보장
    - 데이터를 여러 데이터센터에 다중화
- 쓰기 연산에 대한 높은 가용성 보장
    - 버저닝 및 벡터 시계를 사용한 충돌 해소
- 데이터 파티션
    - 안정 해시
- 점진적 규모 확장성
    - 안정 해시
- 다양성(heterogeneity)
    - 안정 해시
- 조절 가능한 데이터 일관성
    - 정족수 합의(quorum consensus)
- 일시적 장애 처리
    - 느슨한 정족수 프로토콜(sloppy quorum)과 단서 후 임시 위탁(hinted handoof)
- 영구적 장애 처리
    - 머클 트리(Merkle tree)
- 데이터 센터 장애 대응
    - 여러 데이터 센터에 걸친 데이터 다중화