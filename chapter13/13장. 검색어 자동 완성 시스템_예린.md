# 13장. 검색어 자동 완성 시스템
## 목표
가장 많이 이용된 검색어 k개를 자동완성하여 출력하는 시스템을 설계하라.
## 1단계. 문제 이해 및 설계 범위 확정
- 자동완성될 검색어에서 입력하는 단어의 위치: 첫 부분
- 표시할 자동완성 검색어 개수: 5개
- 추천 검색어 기준: 질의 빈도에 따라 정해지는 검색어 인기 순위 기준
- 부가 기능 지원 여부: 맞춤법 검사/자동 수정 등 미지원
- 언어: 영어 우선, 추후 다국어 지원
- 대문자/특수문자 처리: 영소문자 기준
- 사용자 수: DAU 천만 명
### 요구사항
- 빠른 응답 속도
  - 페이스북 검색어 자동완성 시스템에 관한 문서 기준 응답 속도는 100밀리초 이내여야 한다.
- 연관성: 입력한 단어와 연관된 것
- 정렬: 인기도 등의 순위 모델에 의해 정렬
- 규모 확장성
- 고가용성
### 개략적 규모 추정
- DAU: 천만 명
- 사용자 당 검색 횟수: 10건
- 질의 데이터 크기: 20바이트
  - ASCII 기준 1문자 = 1바이트
  - 질의문 당 4개 단어
  - 각 단어 당 5개 글자
- 검색창에 글자 입력할 때마다 백엔드에 요청 전송
  - 1회 검색 당 20건 요청 발생
- QPS = 천만 명 * 10개 질의 / 20자 / 1일 / 24시간 / 3600초 = 24000건/sec
  - 최대 QPS = QPS * 2 = 48000/sec
- 질의 중 20%는 신규 검색어로 가정
  - 천만명 * 10개 질의 / 20자 / 20% / 1일 = 매일 0.4GB의 신규 데이터가 시스템에 추가
## 2단계. 개략적 설계안 제시 및 동의 구하기
- 데이터 수집 서비스: 사용자가 입력한 질의를 실시간으로 수집
- 질의 서비스: 질의에 다섯 개의 인기 검색어 정렬해서 반환
### 데이터 수집 서비스
- 빈도 테이블: 질의문과 사용빈도 저장
### 질의 서비스
- 빈도 테이블에 기록된 수치 기준으로 연산
```sql
SELECT * FROM frequency_table
WHERE query LIKE 'prefix%'
ORDER BY frequency DESC
LIMIT 5
```
- 한계: 데이터 많아지면 병목 발생
## 3단계. 상세 설계
- Trie 자료구조
- 데이터 수집 서비스
- 질의 서비스
- 규모 확장 가능한 저장소
- 트라이 연산
### Trie
#### 구조
- 트리 구조
  - root: 빈 문자열
  - 각 노드: 글자 하나
  - 자식 노드: 최대 26개 (다음 글자로 등장할 수 있는 글자 개수 = 26)
- 각 트리 노드는 하나의 단어, 또는 접두어 문자열을 나타낸다.
- 각 노드에 해당 문자열 이용 빈도를 함께 저장
#### k개 질의 알고리즘
- p: 접두어 길이
- n: 트라이 안에 있는 노드 개수
- c: 주어진 노드의 자식 노드 개수
1. 접두어를 표현하는 노드 탐색: O(p)
2. 하위 트리 중 모든 유효 노드 탐색 (유효 노드 == 유효 검색 문자열을 구성하는 노드): O(c)
3. 유효 노드 정렬하여 가장 인기 있는 검색어 k개 탐색: O(clogc)
- 최악의 경우, 전체 트라이 탐색
- 해결책
  - 접두어 최대 길이 제한
  - 각 노드에 인기 검색어 캐시
#### 접두어 최대 길이 제한
- p값 제한
- 시간 복잡도 = O(p) -> O(1)
#### 노드에 인기 검색어 캐시
- k개 인기 검색어 저장하여 전체 트라이 검색 방지
- 시간 복잡도 = O(clogc) -> O(1)
- 장점: 빠른 응답 속도
- 단점: 각 노드에 질의어 저장할 공간 필요
### 데이터 수집 서비스
#### 실시간으로 데이터 수정 시 문제점
- 매일 수천만 건의 질의 마다 트라이 갱신 시 심한 성능 저하
- 트라이 형성 이후 인기 검색어는 자주 바뀌지 않을 것 -> 트라이 자주 갱신 불필요
- 데이터 수집처: 데이터 분석 서비스 or 로깅 서비스
- 설계안: **데이터 분석 서비스 로그 -> 로그 취합 서버 -> 취합된 데이터 -> 작업 서버 -> 트라이 DB -> 트라이 cache**
#### 데이터 분석 서비스 로그
- 검색창에 입력된 질의 원본 데이터 보관
- only 데이터 추가 (수정 X)
#### 로그 취합 서버
- 데이터 취합 방식
  - 실시간 애플리케이션 (ex: 트위터): 데이터 취합 주기 짧게 가져가 결과를 빨리 보여주기
  - 대부분: 일주일에 한 번이면 충분
- **데이터 취합의 실시간성이 얼마나 중요한지 확인**
#### 취합된 데이터
- {query, time, frequency}
  - query: 질의문
  - time: 해당 주 시작 날짜
  - frequency: 질의가 해당 주에 사용된 횟수
#### 작업 서버
- 주기적으로 비동기적 작업 실행하는 서버 집합
- 트라이 자료구조 만들고 DB에 저장하는 역할
#### 트라이 캐시
- 분산 캐시 시스템
- 트라이 데이터를 메모리에 유지하여 읽기 연산 성능 높임
- 매주 트라이 DB 스냅샷 떠서 갱신
#### 트라이 DB
- 문서 저장소: MongoDB와 같은 저장소에 트라이를 직렬화하여 저장
- 키-값 저장소: <트라이에 보관된 접두어 해시 키, 각 트라이 노드에 보관된 모든 데이터>
### 질의 서비스
1. 검색 질의가 로드밸런서로 전송
2. 로드밸런서는 질의를 API 서버로 전송
3. API 서버는 트라이 캐시에서 데이터 조회해서 자동완성 검색어 제안 응답 구성
4. 트라이에 없는 경우, DB에서 데이터를 가져와 캐시에 채운다.
- 최적화 방안
  - AJAX 요청: 요청을 보내고 받기 위한 페이지를 새로고침하지 않아도 됨
  - 브라우저 캐싱: 대부분의 자동완성 검색어 제안 결과는 짧은 시간에 바뀌지 않는다. 캐시에 넣어두고, 후속 질의의 결과는 캐시에서 바로 사용
    - 구글 검색 엔진: 
      - 제안된 검색어를 한 시간 동안 캐싱
      - cache-control: private -> 해당 응답이 요청을 보낸 사용자의 캐시에만 보관될 수 있으며 공용 캐시에 저장되어서는 안된다.
  - 데이터 샘플링: 모든 질의 결과를 로깅하면 CPU 자원과 저장 공간을 과하게 소진하므로, N개 요청 중 1개만 로깅하도록 샘플링
### 트라이 연산
1. 트라이 생성: 작업 서버가 데이터 분석 서비스 로그나 DB로부터 취합된 데이터 이용
2. 트라이 갱신:
   1. 매주 한 번 갱신: 기존 트라이를 새로운 트라이로 대체
   2. 트라이의 각 노드 개별 갱신
      - 해당 노드의 상위 모든 노드 갱신 필요 -> 성능 저하
3. 검색어 삭제: 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어 필터링
### 저장소 규모 확장
- 첫 글자 기준 샤딩
  - scale-out 한계: 최대 26대
  - 그 이상은 계층적 샤딩 필요
  - 한계: 고르지 않은 데이터 분표 (C로 시작하는 단어 >>> x로 시작하는 단어)
- 샤드 관리자
  - 과거 질의 데이터 패턴 분석하여 샤딩
  - 샤드 관리자가 어떤 검색어가 어느 저장소 서버에 저장되는지 관리
## 4단계. 마무리
- 다국어 지원: 트라이에 유니코드 데이터 저장
- 국가별 인기 검색어 순위 다른 경우: 국가별 트라이 분리, CDN에 저장하여 응답 속도 개선
- 실시간 검색어 추이 반영: 현재 구조로는 무리
  - 샤딩으로 작업 대상 데이터 양 감소
  - 순위 모델로 변경하여 최근 검색어에 높은 가중치 부여
  - 스트림 프로세싱
