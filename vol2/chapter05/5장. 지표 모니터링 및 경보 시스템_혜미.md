# 1. 설계 요구사항
## 모니터링 대상 및 규모
- **목적**: 회사 내부 인프라의 운영 지표(예: CPU 사용률, 메모리 사용량, 요청 수, 메시지 큐 내 메시지 수 등)를 모니터링하여 이상 징후 탐지 및 경보 발생
- **대상**: 내부 시스템 운영 지표만 수집 (사업 지표, 에러/액세스 로그 등은 제외)
- **환경 규모**:
    - 일간 능동 사용자(DAU): 1억 명
    - 서버 풀: 1000개
    - 풀당 서버 수: 100대
    - 서버당 지표 수: 100개
    - **총 모니터링 지표 수**: 약 1000만 개

## 데이터 보관 정책
- **전체 보관 기간**: 1년
- **원시 데이터**: 7일간 보관
- **다운샘플링**:
    - 7일 지난 데이터는 1분 단위 데이터로 변환 → 30일간 보관
    - 그 이후는 1시간 단위 데이터로 변환 → 1년간 보관

## 비기능 요구사항
- **확장성**: 지표 수와 경보 발생량 증가에 따른 원활한 확장
- **낮은 응답 지연**: 대시보드와 경보 질의를 신속하게 처리
- **안정성**: 중요 경보가 누락되지 않도록 높은 신뢰성 보장
- **유연성**: 미래 기술 변화에 따라 파이프라인 및 구성 요소의 손쉬운 확장/변경

# 2. 기본 아키텍처 구성 요소

## 데이터 수집
- **대상**: 애플리케이션 서버, SQL 데이터베이스, 메시지 큐 등
- **수집 방식**:
    - **Pull 모델**:
        - 수집기가 주기적으로 각 서비스의 HTTP 엔드포인트에서 데이터를 가져옴
        - 예: Prometheus
        - 장점: 디버깅과 health check 용이
    - **Push 모델**:
        - 대상 서버 또는 에이전트가 직접 지표 데이터를 전송
        - 예: Amazon CloudWatch, Graphite
        - 장점: 방화벽 등 네트워크 복잡 환경에서 유리, 생명주기가 짧은 프로세스에 적합

## 데이터 전송
- **전송 파이프라인**:
    - Kafka를 중간에 두어 데이터 수집 컴포넌트와 시계열 데이터베이스의 결합도를 낮춤
    - 데이터베이스 장애 시에도 Kafka에 임시 보관된 데이터를 활용하여 복구 가능

## 데이터 저장소
- **시계열 데이터베이스**:
    - 각 지표 데이터를 타임스탬프와 함께 저장
    - 대표적 시스템: InfluxDB, Prometheus
    - 특징: 대량 쓰기 지원, 메모리 캐시와 디스크 저장소 병행, 레이블/태그 기반 인덱싱 제공

## 질의 서비스
- **역할**: 저장된 시계열 데이터를 효율적으로 조회 및 다운샘플링 데이터를 포함한 다양한 시간 범위의 질의 지원
- **구현**: 별도의 질의 전담 서비스 도입 및 캐시 계층 추가로 읽기 부하 스파이크 완화

## 경보 시스템
- **경보 설정 및 처리**:
    - YAML 파일 등으로 경보 규칙을 관리하고 캐시 서버에 저장
    - 경보 관리자가 주기적으로 질의를 통해 임계치 초과 여부 확인 후 경보 이벤트 생성
    - 경보 이벤트는 Kafka 등을 통해 이메일, 전화, 웹훅 등 다양한 채널로 전송
- **실무 적용**: 자체 구축보다는 상용 경보 솔루션 도입이 일반적

## 시각화 시스템
있는거 써라

# 3. 데이터 모델 및 접근 패턴

## 데이터 모델
- **구조**:
    - **Metric Name**: 지표의 고유 이름 
    - **레이블(Label)**: 키-값 쌍으로, 서버(host), 환경(env), 지역(region) 등 추가 정보 제공
    - **데이터 포인트**: <값, 타임스탬프> 쌍의 배열

## 데이터 접근 사례
- **사례 1**: 특정 프로덕션 서버 인스턴스의 CPU 부하 조회 (Metric Name + 레이블 정보)
- **사례 2**: 특정 지역(예: us-west) 내 모든 웹 서버의 지난 10분간 CPU 부하 평균 계산 (Metric Name 및 레이블 기반 집계)

## 데이터 접근 패턴
- **시간 기반 조회**:
    - x축: 시간, y축: 개별 지표 값
    - 특정 시간 구간에 집중되는 읽기 부하가 발생할 수 있음

# 4. 지표 수집 방식 – 풀 모델 vs 푸시 모델

## Pull 모델
- **구현**:
    - 수집기가 서비스 탐색 시스템(SDS; 예: etcd, Zookeeper)을 통해 각 서비스의 엔드포인트 정보를 받아 주기적으로 데이터 수집
    - 안정적 해시 링 등을 사용해 특정 서버 데이터는 항상 한 대의 수집 서버가 담당하도록 분산
- **장점**:
    - 디버깅과 상태 진단 용이
    - HTTP 엔드포인트를 통한 데이터 조회로 신뢰성 높음
- **단점**:
    - 생명주기가 짧은 프로세스의 경우, 수집 전에 종료될 위험 있음

## Push 모델
- **구현**:
    - 대상 서버에 설치된 에이전트가 직접 지표 데이터를 수집기에 전송
    - 로드밸런서와 Auto Scaling 클러스터를 통해 확장 가능하게 구성
- **장점**:
    - 복잡한 네트워크 환경에서도 유연하게 데이터 수신
    - 생명주기가 짧은 프로세스에 적합 (push gateway 도입 가능)
- **단점**:
    - 인증 및 데이터 신뢰성 보장을 위한 별도 제어 필요

# 5. 데이터 전송 파이프라인 및 확장 전략

## 스트림 처리 도입
- **Kafka 활용**:
    - 데이터 수집과 시계열 데이터베이스 사이에 Kafka를 두어 결합도 완화 및 데이터 손실 없이 보관
    - Kafka 파티션을 지표 이름 및 레이블 기반으로 구성하여 집계 및 우선순위 지정 가능

## Kafka 대안
- **예시**:
    - Facebook의 **Gorilla**: 메모리 기반 시계열 데이터베이스 시스템으로, 큐 없이 대규모 데이터 처리 가능

# 6. 데이터 집계 및 저장 최적화

## 집계 전략
- **클라이언트 측 집계**:
    - 에이전트가 단순 집계를 수행하나, 복잡한 로직 지원에는 한계 존재
- **데이터 수집 파이프라인 내 집계**:
    - 저장소 기록 전에 데이터를 집계하여 전송량 감소 효과
- **질의 시 집계**:
    - 원시 데이터를 보존한 상태에서 필요 시점에 집계 (응답 지연 가능)

## 저장소 최적화 기법
- **데이터 인코딩 및 압축**
- **다운샘플링**:
    - 장기 보관 데이터를 해상도 낮춰 저장 용량 및 비용 절감
- **냉동 저장소**:
    - 비활성 데이터를 저비용으로 보관

# 7. 경보 및 시각화 시스템 설계

## 경보 시스템
- **경보 설정 관리**:
    - YAML 파일 등으로 경보 규칙을 관리 후 캐시 서버에 저장
- **경보 처리 흐름**:
    - 주기적으로 질의하여 임계치 초과 여부 확인 후 경보 이벤트 생성
    - 생성된 경보 이벤트는 Kafka 등을 통해 이메일, 전화, PagerDuty, HTTP 웹훅 등 다양한 채널로 전송
- **실무 적용**:
    - 자체 구축보다는 상용 경보 솔루션 도입이 일반적

## 시각화 시스템
- **대시보드 구성**:
    - **지표 대시보드**: 다양한 시간 범위의 지표를 시각화하여 추세 및 문제점 파악
    - **경보 대시보드**: 경보 상태와 이벤트를 실시간 모니터링
- **도구 예시**:
    - Grafana 등 상용 시각화 도구 활용

# 8. 최종 설계 요약

- **설계 범위**:
    - 내부 인프라 모니터링 대상으로 운영 지표만 수집 (로그/분산 추적 등은 제외)
- **핵심 구성 요소**:
    - 데이터 수집: 풀 모델과 푸시 모델 선택
    - 데이터 전송: Kafka 등 스트림 처리 시스템 도입으로 결합도 완화 및 확장성 확보
    - 시계열 데이터베이스: InfluxDB, Prometheus 등을 통한 대량 쓰기 및 실시간 분석 지원
    - 질의 서비스 및 캐시: 읽기 부하 스파이크 완화 및 낮은 응답 지연 보장
    - 경보 시스템: 경보 규칙 기반 주기적 질의 및 다양한 채널을 통한 경보 전송
    - 시각화 시스템: Grafana 등 도구를 통한 실시간 모니터링 결과 시각화

