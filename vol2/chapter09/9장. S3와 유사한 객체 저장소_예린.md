# 9장. S3와 유사한 객체 저장소

## 목표

아마존 S3(Simple Storage Service)와 유사한 객체 저장소 서비스를 설계하라.

- AWS에서 제공하는 RESTful API 기반 인터페이스로 이용 가능한 객체 저장소
    - 2006년: 서비스 시작
    - 2010년: 버전 관리 기능, 버킷 정책, 멀티 파트 업로드 기능 제공
    - 2011년: 서버 측 암호화, 여러 객체 삭제, 객체 만료 등 지원 시작
    - 2014-2015년: 수명 주기 정책, 이벤트 알림, 지역 간 복제 등 기능 도입

### 저장소 시스템 101

- 블록 저장소
    - 물리적: HDD나 SDD처럼 서버에 물리적으로 연결되는 형태의 드라이브가 가장 보편적
        - 원시 블록을 서버에 볼륨 형태로 제공
        - 가장 유연/융통성 높은 저장소
            - 서버는 원시 블록을 포맷하여 파일 시스템으로 이용 or 애플리케이션에 블록 제어권 넘기기 가능
            - 데이터베이스, 가상 머신 엔진 같은 애플리케이션은 원시 블록을 직접 제어하여 최대 성능 끌어냄
    - 네트워크: 고속 네트워크, FC(업계 표준 연결 프로토콜)을 통해 연결 가능 (네트워크 통해 연결되는 블록 저장소도 원시 블록 제공)
- 파일 저장소
    - 가장 널리 사용되는 범용 저장소 솔루션
    - 파일과 디렉터리를 다루기 위한 더 높은 수준의 추상화 제공
    - 계층적 디렉터리 안에 데이터 보관
    - 파일 수준 네트워크 프로토콜로 하나의 저장소를 여러 서버에 동시에 붙일 수 있음
        - 파일 저장소를 사용하는 서버는 블록 제어/포멧 등 작업을 신경 쓸 필요 없음
- 객체 저장소
    - 데이터 영속성을 높이고 대규모 애플리케이션을 지원하며 비용을 낮추기 위해 의도적으로 성능 희생
    - 실시간 갱신이 필요없는 상대적 차가운 데이터 보관에 초점
        - 데이터 아카이브, 백업 용도
    - 모든 데이터를 수평적 구조 내에 객체로 보관
        - 계층적 디렉터리 구조 제공 X
    - 데이터 접근은 RESTful API를 통해서
    - 상대적 느림

### 용어 정리

- 버킷: 객체를 보관하는 논리적 컨테이너
    - 버킷 이름은 전역적으로 유일
- 객체: 버킷에 저장하는 개별 데이터
    - 객체 = 데이터(페이로드) + 메타데이터
        - 데이터: 아무거나 다
        - 메타데이터: 객체를 기술하는 이름-값 쌍의 집합
- 버전: 한 객체의 여러 버전을 같은 버킷 안에 둘 수 있도록 하는 기능
    - 버킷마다 별도 설정 가능
    - 이전 기록 복구
- URI: 버킷과 객체에 접근할 수 있는 RESTful API를 통해 객체를 고유하게 식별
- SLA: 서비스 수준 협약: 서비스 제공자와 클라이언트 사이의 계약
    - AWS S3 Standard-IA 저장소는 다음 SLA를 만족한다.
        - 여러 가용성 구역에 걸쳐 99.999999999%의 객체 내구성을 제공하도록 설계
        - 하나의 가용성 구역 전체가 소실되어도 데이터 복원 가능
        - 연간 99.9%의 가용성 제공

## 1단계: 문제 이해 및 설계 범위 확정

- 기능: 버킷 생성, 객체 업로드/다운로드, 객체 버전, 버킷 내 객체 목록 출력 기능(aws s3 ls 명령어와 유사해야함)
- 데이터 크기: 아주 큰 객체(수 GB 이상), 다량의 소형 객체(수 KB 정도)를 효율적으로 저장
- 매년 추가되는 데이터 양: 100PB
- 가용성: 99.9999%의 데이터 내구성과 99.99%의 서비스 가용성 보장

### 비기능 요구사항

- 100PB 데이터
- 식스 나인 수준의 데이터 내구성
- 포 나인 수준의 서비스 가용성
- 저장소 효율성: 높은 수준의 안정성과 성능은 보장하되, 저장소 비용은 최대한 낮춰야 함

### 대략적인 규모 추정

- 디스크 용량이나 초당 디스크 IO가 병목이 될 가능성이 높음
- 디스크 용량
    - 데이터 분포: 20% = 1MB 미만, 60% = 1MB~64MB 정도 크기, 20% = 64MB 이상
- IOPS: SATA 인터페이스를 탑자해고, 7200rpm을 지원하는 하드 디스크 하나가 초당 100~150회의 임의 데이터 탐색 지원 가정
- 객체 유형별 중간값 활용, 40%의 저장 공간 사용률 유지
    - 100PB = 100 * 1000 * 1000 * 1000 = 10^11MB
    - (10^11 * 0.4) / 0.2*0.5MB + 0.6*32MB + 0.2*200MB = 6억 8천만 개 객체
    - 모든 객체의 메타데이터 크기가 대략 1KB라고 가정 시, 0.68TB 정도의 공간 필요

## 2단계. 개략적 설계안 제시 및 동의 구하기

- 객체 불변성: 객체 저장소와 다른 두 가지 유형의 저장소 시스템의 가장 큰 차이는 객체 저장소에 보관되는 객체들은 변경이 불가능하다는 것, 삭제 후 새 버전 객체로 완전히 대체해야 함
- 키-값 저장소: 해당 객체의 URI로 데이터 조회
- 저장 1회, 읽기 N회: 데이터 접근 패턴 측면에서 쓰기 1회에 읽기 n번 발생한다. (링크드인: 요청 중 95% 가량이 읽기 요청)
- 소형 및 대형 객체 동시 지원: 다양한 크기의 객체를 문제 없이 저장
- 설계: 메타데이터와 실제 데이터를 분리, 메타데이터 저장소에는 네트워크를 통해 데이터 저장소에 보관된 객체를 요청하는 데 필요한 식별자 보관
    - 데이터 저장소의 데이터 -> 불변
    - 메타데이터 저장소의 데이터 -> 가변
    - 두 컴포넌트를 독립적으로 구현하고, 최적화

### 개략적 설계안

<img alt="image" src="https://github.com/user-attachments/assets/63b4f543-06cb-4e7e-b91e-93e842a62a01">

### 객체 업로드

1. 클라이어트: 버킷 생성 요청 -> `HTTP PUT: /bucket-to-share 생성`
2. API 서비스는 IAM 호출하여 사용자가 WRITE 권한 가졌는지 확인
3. API 서비스는 메타데이터 데이터베이스에 버킷 정보 등록 위해 메타데이터 저장소 호출, 만들어지면 그 사실 알리는 메시지를 클라이언트에 전송
4. 버킷 만들어지면 클라이언트는 script.txt 객체를 생성하기 위한 HTTP PUT 요청 전송
5. API 서비스는 해당 사용자 신원 및 WRITE 권한 소유 여부 확인
6. API 서비스는 HTTP PUT 요청 몸체에 실린 객체 데이터를 데이터 저장소로 전송
7. 데이터 저장소는 해당 데이터를 객체로 저장하고 해당 객체의 UUID 반환
8. API 서비스는 메타데이터 저장소를 호출하여 새로운 항목 등록

### 객체 다운로드

1. 클라이언트는 GET /{버킷명}/script.txt 요청을 로드밸런서로 전송, 로드밸런서가 API 서버로 전달
2. API 서비스는 IAM 질의로 사용자가 버킷에 READ 권한 가졌는지 확인
3. 권한 있음 확인 후 API 서비스는 해당 객체의 UUID 메타데이터 저장소를 조회
4. API 서비스는 해당 UUID로 데이터 저장소에서 객체 데이터 조회
5. API 서비스는 HTTP GET 요청에 대한 응답으로 해당 객체 데이터를 반환

## 3단계. 상세 설계

- 데이터 저장소
- 메타데이터 모델
- 버킷 내의 객체 목록 확인
- 객체 버전
- 큰 파일의 업로드 성능 최적화
- 쓰레기 수집

### 데이터 저장소

<img alt="image" src="https://github.com/user-attachments/assets/8de97371-0ffb-46ac-9169-f3f431236376">

### 데이터 저장 흐름

1. API 서비스는 객체 데이터를 데이터 저장소로 포워딩
2. 데이터 라우팅 서비스는 해당 객체에 UUID를 할당하고 배치 서비스에 UUID를 입력으로 주고 질의하면 해당 객체에 대한 다중화 그룹이 반환됨
    - 계산 결과는 결정적, 다중화 그룹이 추가되거나 삭제되는 경우에도 유지
    - 안정 해시 사용
3. 배치 서비스는 가상 클러스터 지도를 확인하고, 데이터 보관할 주 데이터 노드 반환
4. 데이터 라우팅 서비스는 저장할 데이터를 UUID와 함께 주 데이터 노드에 직접 전송
    - 모든 데이터 노드에 강력한 데이터 일관성 보장
    - 가장 느린 사본에 대한 작업이 완료될 때까지 응답을 반환하지 못하므로, 지연 시간 측면에서 손해
5. 주 데이터 노드는 데이터를 자기 노드에 지역적으로 저장, 두 개 부 데이터 노드에 다중화
6. 주 데이터 노드는 데이터를 모든 부 데이터 노드에 성공적으로 다중화하면 데이터 라우팅 서비스에 응답 반환
7. 객체의 ID를 API 서비스에 반환

### 데이터 관리 방법

1. 각각의 객체를 개별 파일로 저장
    - 작은 파일이 많아져 낭비되는 데이터 블록 수 증가: 파일 시스템은 파일을 별도의 디스크 블록으로 저장
    - 시스템의 아이노드 용량 한계를 초과하는 문제: 대부분의 파일 시스템은 디스크 초기화 순간에 사용 가능한 아이노드의 수가 결정되는데, 작은 파일들이 이를 모두 소진시킬 가능성 존재
2. 작은 객체들을 큰 파일 하나로 모아서 저장
    - 1번 문제 해결
    - 개념적으로는 Write-Ahead Log 처럼 객체를 저장할 때 이미 존재하는 파일에 추가하는 방식
    - 용량 임계치에 도달한 파일은 읽기 전용 파일로 변경하고, 새로운 파일 생성
    - 이 레이아웃을 유지하려면 여러 CPU 코어가 쓰기 연산을 병렬로 진행하더라도 객체 내용이 뒤섞이는 일은 없어야 함
    - 현대 많은 코어를 가지는 시스템 -> 쓰기 대여폭 심각하게 줄어듦
    - 따라서, 서버에서 오는 요청을 처리하는 코어별로 전담 읽기-쓰기 파일을 두어야 한다

### 객체 소재 확인

- 특정 파일 안에서 객체를 찾기 위해 필요한 정보: <object-mapping> 테이블
    - UUID
    - 객체 보관된 데이터 파일
    - 데이터 파일내 객체 오프셋
    - 객체 크기
- 정보 저장하는 방법
    - 파일 기반 키-값 저장소 이용
        - 쓰기 성능 좋음, 읽기 성능 느림
    - 관계형 데이터베이스 이용
        - 쓰기 성능 느림, 읽기 성능 좋음
    - **데이터 노드에 저장되는 위치 데이터를 다른 데이터 노드와 공유할 필요 없으므로, 각 데이터 노드마다 관계형 데이터베이스를 설치하자**
        - SQLite: 파일 기반 관계형 데이터베이스

### 개선된 데이터 저장 흐름

1. API 서비스는 새로운 객체를 저장하는 요청을 데이터 노드 서비스에 전송
2. 데이터 노드 서비스는 객체를 읽기-쓰기 파일의 마지막 부분에 추가
3. 해당 객체에 대한 새로운 레코드를 object-mapping 테이블에 추가
4. 데이터 노드 서비스는 API 서비스에 해당 객체의 UUID를 반환

### 데이터 내구성

- 데이터 안정성은 데이터 저장 시스템에서 매우 중요
- 식스 나인 수준의 데이터 내구성을 위해서 **장애가 발생할 모든 경우를 세심하게 살핀 다음 데이터를 적절히 다중화**

#### 하드웨어 장애와 장애 도메인

- 개략적 추정: 회전식 드라이브 연간 장애율이 0.81%라고 가정 -> 데이터를 3중 복제 시 내구성은 1 - 0.0081^3 = 0.999999
- 완전한 내구성 평가를 위해서는 여러 장애 도메인의 영향을 복합적으로 고려
    - 장애 도메인: 중요한 서비스에 문제가 발생했을 때 부정적인 영향을 받는 물리적/논리적 구획
- 여러 AZ에 데이터를 복제해 장애 여파 최소화

#### 소거

- 내구성을 달성하는 다른 방안
- 데이터를 작은 단위로 분할하여 다른 서버에 배치하는 한편, 그 가운데 일부가 소실되었을 때 복구하기 위한 parity 정보를 만들어 중복성을 확보
- 장애가 생기면 남은 데이터 + parity를 조합하여 소실된 부분 복구
- 단점
    - 최대 8개의 건강한 노드에서 데이터를 가져와야 함.
    - 응답 지연 증가하는 대신, 내구성은 향상되고 저장소 비용은 낮아짐
    - 데이터 노드 설계 측면에서 까다로움
- 소거 코드 사용 시 2개 데이터 블록 + 하나의 패리티 블록 필요 -> 오버헤드 = 50%
    - 3중 복제 다중화 방안 -> 200%
- 효과: 노드 연간 장애 발생률이 0.81%일 때, 11-nine의 내구성 달성 가능

** 요약하자면, 응답 지연이 중요한 애플리케이션에는 다중화 방안이, 저장소 비용이 중요한 애플리케이션에는 소거 코드가 적합**

#### 정확성 검증

- 메모리 데이터의 훼손 대처 방법
    - 데이터 훼손 시 검증 위한 체크섬을 두어 해결
- 객체 데이터의 끝에 체크섬을 두어, 파일을 읽기 전용으로 전환하기 직전에 전체 파일의 체크섬을 계산한 다음에 파일 말미에 추가

### 메타데이터 데이터 모델

#### 스카미

- 질의
    - 객체 이름으로 객체 ID 찾기
    - 객체 이름에 기반하여 객체 삽입 또는 삭제
    - 같은 접두어 갖는 버킷 내의 모든 객체 목록 확인

#### bucket 테이블의 규모 확장

- 100만 명의 고객이 10개의 버킷을 갖고 있으며, 한 레코드의 크기는 10KB라고 가정
- 10GB의 저장 공간 필요 -> 전체 테이블은 최신 데이터베이스 서버 한 대에 충분히 저장
- 읽기 요청을 처리하기 위해서는 CPU 용량이나 네트워크 대여폭 부족 가능 -> 사본 만들어 분산

#### object 테이블의 규모 확장

- 객체 메타데이터 보관
- 샤딩을 사용하여 메타데이터 테이블 규모 확장
- 샤딩 키 기준
    1. bucket_id를 기준으로 -> 핫스팟 샤드 문제
    2. object_id를 기준으로 -> 질의 1과 2를 효율적으로 지원하지 못함
    3. bucket_name과 object_name을 결합하여 샤딩 ✅

### 버킷 내 객체 목록 확인

- 객체 저장소는 객체를 파일 시스템처럼 계층적 구조로 보관 X
- S3는 이를 위해 접두어 기준으로 객체를 조회해오는 방법 사용

### 단일 데이터베이스 서버

```sql
SELECT *
FROM object
WHERE bucket_id = "123"
  AND object_name LIKE 'abc/%'
```

- 같은 접두어를 갖는, 버킷 내 모든 객체를 출력

### 분산 데이터베이스

- 메타데이터 테이블을 샤딩하면 어떤 샤드에 데이터가 있는지 모르기 때문에 목록 출력 기능을 구현하기 어려움

1. 모든 샤드에 질의를 돌려 결과를 취합하자.
    - 페이징 구현의 어려움
2. 페이징 구현 문제를 해결하기 위한 방법:

- 객체 저장소는 규모와 내구성 최적화에 치중하고, 객체 목록 출력 명령의 성능을 보장하는 것은 우선순위가 높지 않음
- 그러므로, 버킷 ID로 샤딩하는 별도 테이블에 목록 데이터를 비정규화하는 것도 방법 -> 객체 목록 출력 시에는 해당 테이블 데이터만 사용하는 것

### 객체 버전

- 버킷 안에 한 객체의 여러 버전을 둘 수 있도록 하는 기능
- 객체 저장소는 해당 문서의 모든 이전 버전을 메타 데이터 저장소에 유지하고, 이전 버전에 학제 표시를 하지 않음

#### 동작 과정

1. 클라이언트는 스크립트 객체를 업로드하기 위한 HTTP PUT 요청 전송
2. API 서비스는 사용자 신원 확인 및 쓰기 권한 보유 여부 확인
3. 확인 결과 문제가 없으면 API 서비스는 데이터를 데이터 저장소에 업로드
4. 데이터 저장소는 새 객체를 만들어 데이터를 영속적으로 저장하고 API 서비스에 새로운 UUID 반환
5. API 서비스는 메타데이터 저장소를 호출하여 새 객체의 메타데이터 정보를 보관
6. 버전 기능을 지원하기 위해 메타데이터 저장소의 객체 테이블에는 object_version이라는 이름의 열에 새로운 레코드가 테이블에 추가될 때 만들어지는 TIMEUUID 값을 저장
7. 객체 삭제 시에는 가장 최근 버전에 논리적 삭제

### 큰 파일의 업로드 성능 최적화

- 멀티파트 업로드: 큰 객체는 작게 쪼갠 다음 독립적으로 업로드하자.

1. 클라이언트가 멀티파트 업로드를 시작하기 위해 객체 저장소 호출
2. 데이터 저장소가 uploadID(해당 업로드를 유일하게 식별할 ID) 반환
3. 클라이언트는 파일을 작은 객체로 분할한 뒤 업로드 시작
4. 조각 하나가 업로드 될 때마다 데이터 저장소는 업로드가 정상적으로 되었는지 검사하기 위한 ETag 반환
5. 모든 조각을 업로드하고 나면 클라이언트는 멀티파트 업로드를 종료하라는 요청 전송
    - uploadID, 조각 번호 목록, ETag 목록 포함하여 전송
6. 데이터 저장소는 전송 받은 조각 번호 목록을 사용해 원본 객체를 복원, 끝나면 성공 메시지 반환

### 쓰레기 수집

- 더 이상 사용되지 않는 데이터에 할당된 저장 공간을 자동으로 회수하는 절차
    - 객체의 지연된 삭제: 삭제했다고 표시는 하지만 실제로 지우진 않는다
    - 갈 곳 없는 데이터: 반쯤 업로드된 데이터, 또는 최소된 멀티파트 업로드 데이터
    - 훼손된 데이터: 체크섬 검사에 실패한 데이터
- 객체를 데이터 저장소에서 바로 지우지 않고, 삭제된 객체는 정리 메커니즘을 주기적으로 실행하여 지움
- 사용되지 않는 사본에 할당된 저장 공간을 회수하는 역할도 담당

1. 쓰레기 수집기는 삭제 대상이 아닌 객체를 다른 곳으로 복사
2. 모든 객체를 복사한 다음 쓰레기 수집기는 object_mapping 테이블을 갱신, file_name과 start_offset으 ㅣ값도 새 위치를 가리키도록 수정

- 작은 파일을 많이 만들지 않기 위해 쓰레기 수집기는 보통 압축할 읽기 전용 파일이 많아질 때까지 기다림
- 압축을 진행하면서 여러 읽기 전용 파일에 기록된 객체를 하나의 파일로 모음
