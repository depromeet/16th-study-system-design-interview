# 4장. 처리율 제한 장치의 설계

## 처리율 제한 장치
- 네트워크 시스템에서 클라이언트나 서비스가 보내는 트래픽 처리율을 제어하기 위한 장치
- 예시
    - 트위터는 3시간 동안 300개의 트윗만 올릴 수 있도록 제한
    - 구글 독스 API는 사용자당 분당 300회의 read 요청만 허용
- 이점
    - 추가 요청에 대해 처리를 중단하여 **DoS 공격에 의한 자원 고갈 방지**
    - 과금이 발생하는 API에 대해 횟수를 제한하여 **비용 절감**
    - 잘못된 트래픽을 걸러내어 **서버 과부하 방지**
## 처리율 제한 알고리즘
### 토큰 버킷 알고리즘
- 간단, 알고리즘에 대한 세간의 이해도 높은 편, 보편적으로 사용
- 동작 원리
    - 토큰 버킷
        - 지정된 용량을 갖는 컨테이너
        - 사전에 설정된 양의 토큰이 `토큰 공급기`에 의해 주기적(ex: 매초 2회) 채워진다.
        - overflow는 버려진다.
    - 요청 처리
        - 요청 당 하나의 토큰 사용
        - 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼내 요청을 시스템에 전달
        - 충분한 토큰이 없는 경우, 해당 요청은 버려진다.
- 인자
    - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
    - 토큰 공급률: 버킷에 공급되는 초당 토큰 개수
- 버킷 개수: 목적에 따라 API 엔드포인트마다, IP 주소마다 버킷을 사용
- 장점
    - 구현 쉬움
    - 메모리 사용 측면에서 효율적
    - **짧은 시간에 집중되는 트래픽 처리 가능**
- 단점
    - 버킷 크기와 토큰 공급률을 적절하게 튜닝하는 것이 까다로움
### 누출 버킷 알고리즘
- 토큰 버킷 알고리즘과 유사하지만, 요청 처리율이 고정
- FIFO 큐로 구현
- 동작 원리
    - 요청이 도착하면 큐가 가득 차 있는지 확인
    - 빈 자리가 있는 경우, 큐에 요청 추가
    - 큐가 가득찬 경우, 새 요청은 버려진다.
    - 지정된 시간마다 큐에서 요청을 꺼내어 처리
- 인자
    - 버킷 크기: 큐 사이즈와 같은 값, 큐에는 처리될 항목 보관
    - 처리율: 지정된 시간당 몇 개의 항목 처리할지 지정, 보통 초 단위
- 장점
    - 큐 크기가 제한되어 있으므로 메모리 사용량 측면에서 효율적
    - 고정 처리율이므로 **안정적 출력이 필요한 경우에 적합**
- 단점
    - 단시간에 트래픽이 몰리는 경우 요청을 제때 처리 못하면 최신 요청들이 버려진다.
    - 두 개 인자 튜닝의 까다로움
### 고정 윈도우 카운터 알고리즘
- 동작원리
    - 타임라인을 고정된 간격의 윈도우로 나누고, 각 윈도우마다 카운터를 부친다.
    - 요청이 접수될 때마다 카운터의 값 1씩 증가
    - 카운터 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴 때까지 버려진다.
- 장점
    - 메모리 효율적
    - 이해하기 쉬움
    - **윈도우가 닫히는 시점에 카운터를 초기화하는 방식은 특정 트래픽 패턴을 처리하기에 적합**
- 단점
    - 경계 부근에 순간적으로 트래픽이 집중되면 윈도우에 할당된 양보다 많은 요청이 처리될 수 있다.
### 이동 윈도우 로깅 알고리즘
- 윈도우 경계 부근에 트래픽이 집중되는 경우 시스템에 설정된 한도보다 많은 요청을 처리하는 고정 윈도우 알고리즘의 문제점을 해소
- 동작 원리
    - 요청 타임스탬프 추적
        - 타임스탬프 데이터는 레디스 같은 캐시에 보관
    - 새 요청이 오면 만료된 타임 스탬프 제거
        - 만료된 타임스탬프: 현재 윈도우 시작 시점보다 오래된 타임스탬프
    - 새 요청의 타임ㅅ탬프를 로그에 추가
    - 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달, 그 외 거부
- 예시: 분당 최대 2회 처리
  
  <img width="500" alt="image" src="https://github.com/user-attachments/assets/c5486b70-3717-4e97-86ca-bb1e02f6c95b" />

- 장점
    - 정교함
    - **어느 순간의 윈도우를 보더라도, 허용되는 요청의 개수는 시스템 처리율 한도를 넘지 않는다.**
- 단점
    - 다량의 메모리 사용 (거부된 요청 타임스탬프도 보관)
### 이동 윈도우 카운터 알고리즘
- 고정 윈도우 카운터 알고리즘 + 이동 윈도우 로깅 알고리즘
- 동작 원리
    - 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도우 직전 1분이 겹치는 비율
- 예시
    - 분당 7개 요청 처리
    - 직전 1분 간 5개의 요청이, 현재 1분간 3개의 요청이 왔다고 가정
    - 현재 1분의 30% 시점에 도착한 새 요청은, 현재 윈도에 몇 개의 요청이 온 것으로 보고 처리해야 할까?
    - **3 + 5 * 70% = 6.5**이므로, 현재 1분의 30% 시점에 도착한 신규 요청은 시스템으로 전달될 것이다. 하지만, 그 직수에는 한도에 도달하여 더 이상 요청을 받을 수 없을 것이다.
- 장점
    - 이전 시간대의 평균 처리율에 따라 윈도우의 상태를 계산하므로 **짧은 시간에 몰리는 트래픽에도 잘 대응**
    - 메모리 효율적
- 단점
    - 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하므로 다소 느슨할 수 있지만, 큰 문제는 아님
## 처리율 제한 장치 설계하기
### 1단계. 문제 이해 및 설계 범위 확정
#### 면접관과의 소통
- 서버측 제한 장치
- 다양한 형태의 제어 규칙(IP, 사용자 ID 등)을 정의할 수 있는 유연한 시스템
- 대규모 요청을 처리할 수 있어야 함
- 분산 환경에서 동작해야 함
- 제한 걸린 사용자에게 알림
#### 요구사항
- 설정된 처리율을 초과하는 요청은 정확하게 제안
- HTTP 응답 시간에 영향 주지 않을 **낮은 응답 시간**
- 가능한 **적은 메모리** 사용
- 여러 서버나 프로세스에서 공유 가능한 **분산형 처리율 제한**
- 사용자에게 요청 제한을 분명히 보여주는 **예외 처리**
- 제한 장치에 장애가 생겨도 전체 시스템에는 영향 없는 **높은 결함 감내성**
### 2단계. 개략적 설계안 제시 및 동의 구하기
#### 장치는 어디에?
- 클라이언트에
    - 불안정적
    - 위변조 쉬움
    - 구현 통제의 어려움
- 서버에
    1) API 서버에 제한 장치 위치
       <img width="500" alt="image" src="https://github.com/user-attachments/assets/2dc7574b-c36d-4620-8434-7d796ae3d09f" />

    2) 처리율 제한 장치 미들웨어 생성
       <img width="500" alt="image" src="https://github.com/user-attachments/assets/a6c88362-749b-4433-b433-99c8e6167cfc" />
       <img width="500" alt="image" src="https://github.com/user-attachments/assets/29b295c7-56d4-42a5-bff8-758d48e0391d" />

        - 보통 API 게이트웨이라고 불리는 컴포넌트에 처리율 제한 장치를 구현
          > **API 게이트웨이**
          처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 fully managed 서비스

    - 그래서 처리율 제한 기능은 어디에 둬야 하나? 정답은 없다.
    - 고려 사항
        - 현재 사용 중인 기술 스택 점검: 현재 사용하는 스택이 서버 측 구현을 지원하기 충분할 정도로 효율이 높은가?
        - 적합한 처리율 제한 알고리즘 선정
        - API 게이트웨이 사용: 이미 API 게이트웨이를 설계에 포함시켰는가? 처리율 제한 장치를 구현할 충분한 인력이 없는가?
#### 개략적인 아키텍처
- 얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상별로 두고, 이 카운터의 값이 어떤 한도에 넘어서면 요청을 거부하는 것이다.
- 카운터는 어디에 보관할 것인가?
    - 메모리상에서 동작하는 캐시가 빠르면서 시간 기반 만료 정책을 지원하므로 적합
      <img width="500" alt="image" src="https://github.com/user-attachments/assets/e4cda81f-aace-4c61-a254-0938291494db" />

### 3단계. 상세 설계
- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 처리가 제한된 요청들은 어떻게 처리되는가?
#### 처리율 제한 규칙
- 보통 설정 파일 형태로 디스크에 저장
#### 처리율 한도 초과 트래픽 처리
- 클라이언트는 본인의 요청이 처리율 제한에 걸리고 있는지를 어떻게 감지할 수 있나?
- 자기 요청이 처리율 제한에 걸리기까지 얼마나 많은 요청을 보낼 수 있는지 어떻게 알 수 있나?
- HTTP 헤더
    - `X-Ratelimit-Remaining`: 윈도우 내에 남은 처리 가능 요청 수
    - `X-Ratelimit-Limit`: 매 윈도우마다 클라이언트가 전송할 수 있는 요청 수
    - `X-Ratelimit-Retry-After`: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
      <img width="500" alt="image" src="https://github.com/user-attachments/assets/0695f0d7-17f9-4c9c-982e-10b2a299ab9d" />

#### 분산 환경에서의 처리율 제한 장치 구현
- 경쟁 조건
    - 해결책
        - 락: 시스템 성능 저하 문제
        - 루아 스크립트
        - 정렬 집합 (레디스 자료구조)
- 동기화
    - 대규모 트래픽 처리를 위해서는 한 대의 처리율 제한 장치 서버로는 충분하지 않을 수 있다.
    - 따라서, 여러 대 두게 되면 동기화 필요
    - 해결책
        - 고정 세션
            - 같은 클라이언트로부터 온 요청은 항상 같은 처리율 제한 장치로 전송
            - 규묘면에서 확장 가능하지도 않고, 유연하지도 않음
        - 중앙 집중형 데이터 저장소
            - ex) 레디스
#### 성능 최적화
- 여러 데이터센터 지우너 시 지연시간 증가 문제
- 제한 장치 간 데이터 동기화 시 최종 일관성 모델 사용
#### 모니터링
- 채택된 처리율 제한 알고리즘이 효과적인가?
- 정의한 처리율 제한 규칙이 효과적인가?
### 4단계. 마무리
- 추가 고려 사항
    - 경성/연성 처리율 제한
    - 다양한 계층에서의 처리율 제한
    - 처리율 제한을 회피하는 방법. 클라이언트는 어떻게 설계하는 것이 최선인가?
        - API 호출 횟수 최소화
        - 예외 상황으로부터 우아하게 복구
        - 재시도 로직 구현 시 충분한 백오프 시간
