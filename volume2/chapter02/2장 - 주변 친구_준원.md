# 2장 - 주변 친구
- 1장의 근접성 서비스와의 차이는 사업장 주소는 정적이지만, 주변 친구의 위치는 동적이라는 점이다.

## 1단계 - 문제 이해 및 설계 범위 확정
- 질의응답
  - Q) 지리적으로 얼마나 가까워야 '주변에 있다'고 하는가?
    - A) 5마일, 수치는 설정 가능함
  - Q) 그 거리가 두 사용자 사이의 직선거리로 가능하는가?
    - A) 넹
  - Q) 얼마나 많은 사용자가 해당 앱을 사용하는가? 10억명에 10% 정도가 해당 기능을 사용한다고 가정해도 되는가?
    - A) 넹
  - Q) 사용자의 이동 이력을 보관해 두는가?
    - A) 넹
  - Q) 친구 관계에 있는 사용자가 10분 이상 비활성 상태면 해당 사용자가 사라지는가, 아니면 마지막 위치를 표시하는가?
    - A) 사라지게 함
  - Q) GDPR(General Data Protection Regulation)이나 CCPA(California Consumer Privacy Act)와 같은 규정을 준수하는가?
    - A) 일단은 생략함
- 기능 요구 사항
  - 사용자는 모바일 앱에서 주변 친구를 확인할 수 있어야 함.
  - 각 친구와의 거리와 마지막 갱신 시각을 함께 표시
- 비기능 요구 사항
  - 낮은 지연 시간
  - 안정성
  - 결과적 일관성
    - 위치 데이터에 강한 일관성까지는 필요 없음. 어느정도 시간이 걸리는 것도 용인함

### 개략적 규모 추정
- 주변 친구는 5마일(8km) 반경 이내 친구로 정의
- 위치 정보는 30초 주기로 갱신
- 주변 친구 검색 기능을 활용하는 사용자는 1억명으로 가정
- 동접자수는 DAU의 10%, 1천만명으로 가정
- 평균적으로 한 사용자는 400명의 친구를 갖는다고 가정, 모든 사용자가 주변 친구 검색 기능을 활용한다고 가정
- 페이지 당 20명의 주변 친구를 표시하고, 사용자 요청이 있으면 더 많은 친구를 표시
- QPS : 약 334_000
  - DAU 1억
  - 동시 접속 1천만
  - 30초마다 자기 위치를 시스템에 전송
  - 1천만 / 30초 = 334_000

## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 개략적 설계안
- P2P를 활용한 방시긍로도 해결 가능함.
  - 모바일 단말은 연결 상태가 좋지 않을 수도 있고, 사용할 수 있는 전력이 충분하지 않아서 실용적인 아이디어는 아님
- 공용 백엔드를 사용하면 좀 더 실용적으로 처리 가능
  - 공용 백엔드의 역할
    - 모든 활성 상태 사용자의 위치 정보를 수신
    - 위치 변경 내역 수신 시 마다 사용자의 모든 활성 상태 친구를 찾아 해당 단말로 변경 내용을 전달
    - 두 사용자 사이 거리가 임계치보다 멀면 변경 내용 전송X
    - 큰 규모에서는 적용하지 쉽지 않음.
      - 30초 마다 갱신 -> 초당 334_000번의 위치 정보 갱신
      - 400명의 친구, 10% 활성 상태일 경우 초당 334_000 * 400 * 0.1 = 13_360_000번의 메시지 전송

### 설계안
- 우선 소규모 백엔드를 위한 설계안으로 시작
- 로드밸런서
  - RESTful API 서버 및 양방향 유상태(stateful) 서버로 트래픽을 분산
- RESTful API 서버
  - 무상태 API 서버 클러스터
  - 통상적인 요청/응답 트래픽을 처리
- 웹소켓 서버
  - 친구 위치 정보 변경을 실시간 처리하는 유상태 서버 클러스터
  - 각 클라이언트는 한 서버와 웹소켓 연결을 지속적으로 유지
- 레디스 위치 정보 캐시
  - 활성 상태 사용자의 가장 최근 위치 정보 캐시
  - 레디스 내에 TTL(Time To Live)를 사용해 비활성 상태 유저의 정보는 캐시에서 삭제
  - 레디스 외에도 TTL 지원하는 key-value 저장소는 캐시로 활용 가능
- 사용자 DB
  - 사용자 데이터와 친구 관계 정보 등을 저장
  - RDB, NoSQL 어느 쪽이든 사용 가능
- 위치 이동 이력 DB
  - 사용자 위치 변동 이력을 보관
  - 주변 친구 표시와 직접 관계된 것은 아님
- 레디스 펍/섭(Pub/Sub) 서버
  - 초경량 메시지 버스(message bus)
  - 아주 싼 값에 새로운 채널 생성 가능
  - GB급 메모리를 갖춘 최신 레디스 서버는 수백만 개의 채널을 생성 가능
  - 웹소켓 서버를 통해 수신한 사용자의 위치 정보 변경 이벤트를 배정된 펍/섭 채널에 발행
  - 해당 사용자의 친구 각각과 연결된 웹소켓 연결 핸들러는 해당 채널의 구독자로 설정됨
  - 특정 사용자 위치가 바뀌면 모든 친구의 웹소켓 연결 핸들러 호출
- 주기적 위치 갱신
  - 모바일 클라이언트는 항구적으로 유지되는 웹소켓 연결을 통해 주기적으로 위치 변경 내역을 전송
  - 모바일 클라이언트가 위치 변경 사실을 로드밸런서에 전송
  - 로드밸런서는 해당 클라와 웹소켓 서버 사이 연결을 통해 웹소켓 서버로 보냄
  - 웹소켓 서버는 해당 이벤트를 위치 이동 이력 DB에 저장
  - 웹소켓 서버는 세 위치를 위치 정보 캐시에 보관, TTL도 새롭게 갱신
  - 웹소켓 서버는 레디스 펍/섭 서버의 해당 사용자 채널에 새 위치를 발행
  - 레디스 펍/섭 채널에 발행된 이벤트는 모든 구독자에게 브로드캐스트됨.(온라인 상태 유저)
  - 메시지를 받은 웹소켓 서버는 '위치를 보낸 사용자'와 '받은 사용자' 사이의 거리를 계산
  - 사용자 검색 반경을 넘으면 갱신하지 않고, 거리 내 일 경우 갱신함

### API 설계
- 웹소켓
  - 위치 정보 변경 내역을 전송하고 수신
- 필요한 API
  - [서버] 주기적인 위치 정보 갱신
    - 요청 : 클라이언트는 위도, 경도 시각 정보를 전송
    - 응답 : 성공/실패
  - [클라이언트] 클라이언트가 갱신된 친구 위치를 수신하는 데 사용할 API
    - 전송되는 데이터 : 친구 위치 데이터와 변경된 시각을 나타내는 타임스탬프
  - [서버] 웹소켓 초기화 API
    - 요청 : 클라이언트는 위도, 경도 시각 정보를 전송
    - 응답 : 클라이언트는 자기 친구들의 위치 데이터를 수신
  - [클라이언트] 새 친구 구독 API
    - 요청 : 웹소켓 서버는 친구 ID 전송
    - 응답 : 가장 최근 위도, 경도, 시각 정보 전송
  - [클라이언트] 구독 해지 API
    - 요청 : 웹 소켓 서버는 친구 ID 전송
    - 응답 : 성공/실패
  - HTTP 요청
    - API 서버는 친구 추가/삭제 등의 일반적인 작업 처리

### 데이터 모델
- 위치 정보 캐시
  - key : 사용자 ID
  - value : 위도, 경도, 시각 정보
- 위치 정보 저장에 DB를 사용하지 않는 이유
  - 사용자의 **현재 위치**만 사용
  - 사용자 위치를 가장 최신 하나만 사용하므로 읽기/쓰기 연산이 빠른 레디스가 적합함
  - 위치 정보에 대해서 영속성을 보장할 필요가 없음.
- 위치 이동 이력 DB
  - 위치 이동 이력에 대해서는 막대한 쓰기 연산 부하를 감당할 수 있어야 함
  - 카산드라 DB가 목적에 부합할 수 있음
  - RDB는 한 대에 보관하기에 너무 많아서 샤딩이 필요할 수 있음.

## 3단계 - 상세 설계
### 중요 구성요소별 규모 확장성 - API 서버
- 무상태 서비스이므로 쉽게 확장 가능

### 중요 구성요소별 규모 확장성 - 웹소켓 서버
- 규모를 자동으로 늘리는 건 어렵지 않음.
- 유상태 서버라 기존 서버 제거에는 주의가 필요함
- 서버 노드를 제거하기 전 기존 연결부터 종료해야함
  - 로드밸런서가 인식하는 노드 상태를 '연결 종료 중(draining)'으로 변경
  - 새로운 연결은 만들어지지 않음
  - 모든 연결이 종료되면 서버 제거

### 중요 구성요소별 규모 확장성 - 클라이언트 초기화
- 모바일 클라이언트는 웹소켓 서버 하나와 지속성 웹소켓 연결을 맺음.
- 위치 정보를 받은 웹소켓의 동작
  - 위치 정보 캐시에 보관된 사용자 위치 갱신
  - 위치 정보는 계산에 사용하기 위해 변수에 저장
  - DB에서 사용자의 모든 친구 정보를 가져옴
  - 위치 정보 캐시에 일괄 요청을 보내 모든 친구의 위치를 한 번에 가져옴.
    - TTL은 비활성화 타임아웃 시간(intactivity timeout period)와 동일한 값이므로, 모든 값은 활성 사용자의 값임
  - 캐시가 돌려준 각각의 위치 정보에 대해 거리를 계산
    - 거리 반경 내인 정보만 클라에게 반환
  - 웹소켓 서버는 각 친구의 레디스 서버 펍/섭 채널을 구독
    - 레디스 펍/섭 서버는 저렴해서 활성 여부와 관계 없이 모든 친구를 구독 가능
  - 사용자의 현재 위치를 레디스 펍/섭 서버의 전용 채널을 통해 모든 친구에게 전송

### 중요 구성요소별 규모 확장성 - 사용자 DB
- 두가지 종류의 데이터가 보관
  - 사용자 상세 정보
  - 친구 관계 데이터
- 사용자 ID를 기준으로 데이터를 샤딩

### 중요 구성요소별 규모 확장성 - 위치 정보 캐시
- 활성 상태 유저 위치 정보를 캐시하기 위해 레디스 사용
- 각 항목의 키에는 TTL을 설정
- 위치 정보 갱신 시 TTL도 초기화
- 위치 정보 보관에 100바이트가 필요하다고 가정하면 천 만명의 유저 정보도 한 대의 레디스 서버로도 보관 가능
  - 수GB 정도 메모리만 있으면 됨
- 천 만명의 활성 유저가 30초마다 위치 정보를 갱신하면 초당 334k의 연산을 하게 되어 부담될 수 있음.
- 사용자 ID를 기준으로 샤딩 가능

### 중요 구성요소별 규모 확장성 - 레디스 펍/섭 서버
- 모든 온라인 친구에게 보내는 위치 변경 내역 메시지 라우팅 계층으로 활용
- 채널을 만드는 비용이 저렴해서 레디스 펍/섭 서버를 사용함
- 구독자가 없는 채널로 전송된 메시지는 버려지는데, 서버에 가해지는 부하는 거의 없음
- 채널 하나를 유지하기 위해 구독자 관계를 추적하기 위한 해시 테이블과 연결 리스트가 필요함
  - 아주 소량의 메모리만 사용
  - 오프라인 사용자라 변경이 없는 채널은 생성 이후 CPU 자원을 전혀 사용하지 않음
    - 모든 사용자에게 채널 하나씩 부여
    - 온/오프라인에 상관 없이 모든 구독 관계를 설정
    - 이렇게 하면 활성 여부와 상관 없이 구현이 간단해짐
    - 다만, 더 많은 메모리를 사용하게 됨
      - 메모리가 병목 될 가능성은 낮음

### 중요 구성요소별 규모 확장성 - 얼마나 많은 레디스 펍/섭 서버가 필요한가?
- 메모리 사용량
  - 사용자에게 채널 하나씩 할당 시 전체 채널 수는 1억(10억 사용자의 10%)
  - 사용자의 활성 친구 중 100명이 주변 친구 기능을 사용한다고 가정
  - 구독자 한 명을 추적하기 위해 내부 해시 테이블과 연결 리스트에 20바이트 상당의 포인터들을 저장한다고 가정
  - 모든 채널 저장에 200GB의 메모리 필요
    - 1억 * 20바이트 * 100명의 친구 / 10^9 = 200GB
  - 100GB 메모리 설치 가능한 최신 서버의 경우 모든 채널 보관에 레디스 펍/섭 서버 두 대면 해결됨
- CPU 사용량
  - 펍/섭 서버가 구독자에게 전송해야하는 위치 정보 업데이트 양은 초당 1400만 건에 달함
  - 보수적으로 서버 한 대가 10만개의 구독자 수를 감당한다고 하면 140대의 레디스 서버가 필요함
    - 1400만 / 100_000 = 140대
  - 레디스 펍/섭 서버의 병목은 메모리가 아니라 CPU 사용량임
  - 분산 레디스 펍/섭 클러스터가 필요함
  
### 중요 구성요소별 규모 확장성 - 분산 레디스 펍/섭 서버 클러스터
- 모든 채널이 독립적임
  - 사용자 ID를 기준으로 샤딩
  - 서비스 탐색(service discovery) 컴포넌트를 도입
    - etcd, 주키퍼 등
    - 가용한 서버 목록을 유지하는 기능 및 해당 목록을 갱신하는 데 필요한 UI나 API
      - 설정(configuration) 데이터를 보관하기 위한 소규모 key-value 저장소
    - 클라이언트(웹소켓 서버)로 하여금 '값'에 명시된 레디스 펍/섭 서버에서 발생한 변경 내역을 구독할 수 있는 기능
    - key에 달린 value에는 활성 상태의 모든 레디스 펍/섭 서버로 구성된 해시 링에 보관
      - 1권 5장에 나왔던 안정 해시 설계 부분 참고
  - 웹소켓 서버가 특정 사용자 채널에 위치 정보 변경 내역을 발행하는 과정
    - 웹소켓 서버는 해시 링을 참조해 메시지를 발행할 펍/섭 서버를 선정
      - 서비스 탐색 컴포넌트에 정보가 저장되어 있는데, 성능을 높이고 싶으면 해시 링 사본을 웹소켓 서버에 캐시할 수 있음. 다만, 링 원본에 구독 관계를 설정해 사본의 상태를 항상 원본과 동일하게 해야함
    - 웹소켓 서버는 해당 서버가 관리하는 사용자 채널에 위치 정보 변경 내역을 발행
    - 구독한 채널이 존재하는 레디스 펍/섭 서버를 찾는 과정도 동일함

### 중요 구성요소별 규모 확장성 - 레디스 펍/섭 서버 클러스터의 규모 확장 고려사항
- 레디스 펍/섭 서버 클러스터의 속성
  - 채널에 전송되는 메시지는 메모리나 디스크에 지속적으로 보관되지 않음.
    - 모든 구독자에게 전송 시 삭제됨.(구독자가 없으면 바로 삭제)
    - 채널을 통해 처리되는 데이터가 무상태라고 할 수 있음
  - 채널에 대한 상태 정보는 보관함
    - 각 채널의 구독자 목록은 그 상태 정보의 핵심임
    - 특정 채널을 담당하던 서버가 교체되거나 해시 링에서 제거되는 등의 경우 다른 서버로 이동시키고 해당 채널의 모든 구독자에게 이를 알려야 함
    - 이런 이유로 펍/섭은 유상태 서버임
- 레디스 펍/섭 서버 클러스터는 **유상태 서버 클러스터**로 처리하는 것이 옳음
  - 유상태 서버 클러스터 규모를 늘리거나 줄이는 것은 운영 부담과 위험이 큰 작업임
  - 혼잡한 시간대 트래픽을 무리 없이 감당하고 불필요한 크기 변화를 피하도록 어느 정도 여유를 두고 오버 프로비저닝(over provi-sioning)하는 것이 좋음
  - 불가피하게 규모를 늘릴 경우 주의할 문제
    - 클러스터 크기 조정 시 많은 채널이 해시 링 위의 다른 서버로 이동할 수 있음
      - 링이 갱신되면 엄청난 재구독(resubscription) 부하가 발생할 수 있음
    - 재구독 처리로 인해 새로운 위치 정보 변경 메시지가 누락될 수 있음
      - 어느 정도는 허용할 수 있지만, 최소화할 수 있어야 함
    - 서비스의 상태가 불안정해질 수 있으므로 부하가 가장 낮은 시간에 해야 함
- 클러스터 크기 조정
  - 새로운 링 크기를 계산
    - 크기가 늘어날 경우 새 서버를 준비
  - 해시 링의 키에 달린 값을 새로운 내용으로 갱신
  - 대시보드를 모니터링 해 웹소켓 클러스터의 CPU 사용량이 어느정도 튀는 것이 보야아 함.

### 중요 구성요소별 규모 확장성 - 운영 고려사항
- 기존 레디스 펍/섭 서버를 새 서버로 교체할 때 발생하는 문제는 클러스터 크기 조정보다 훨씬 낮음
  - 채널의 대규모 이동 사태가 없음
- 다만, 서버 장애는 생기게 되어 있고 그런 서버는 일상적으로 교체해야 함
- 펍/섭 서버 장애 시 모니터링 소프트웨어는 엔지니어에게 경보를 발송해야함
- 노드 교체 시 모든 웹소켓 서버에 통지하고 새 채널 구독을 알려야 함.
- 웹소켓 서버로부터 통지를 받으면 모든 채널을 해시 링과 대조해 새 서버로 구독 관계 설정을 해야하는지 검토함

### 친구 추가/삭제
- 사용자가 친구를 추가하거나 제거하면 웹소켓 서버의 연결 핸들러에게 알려야 함
- 웹소켓 서버로 새 친구의 펍/섭 채널을 구독하라는 메시지를 보내야 함
- 친구 삭제도 마찬가지임

### 친구가 많은 사용자
- 친구가 많은 사용자가 시스템 성능 문제를 야기할 수 있는가?
- 최대 친구 수에 상한이 있다고 가정(페이스북은 5000명)
- 친구 관계는 양방향임
  - 100만 팔로워는 존재할 수 없음
- 친구 구독에 필요한 펍/섭 구독 관계는 여러 웹소켓 서버에 분산되어 있음.
  - 친구 위치 변경에 따른 부하는 여러 웹소켓 서버에 분할되어 있으므로 핫스팟 문제는 발생하지 않을 것임

### 주변의 임의 사용자
- 기존 설계를 최대한 활용할 경우 지오해시에 따라 구축된 펍/섭 채널 풀을 두는 것임
  - 지오해시의 각 격자에 채널을 하나씩 만듦.
  - 해당 격자 내의 모든 사용자가 해당 격자 채널을 구독하게 함.
  - 격자 경계 부근 사용자 처리를 위해 사용자가 위치한 지오해시뿐 아니라 주변 지오해시도 구독함.

### 펍/섭 외의 대안
- 레디스 펍/섭 외의 대안은 없는가?
- 얼랭(Erlang)은 유용한 해결책이 될 수 있음
  - 다만 얼랭은 사용자가 많지 않은 언어라서 좋은 프로그래머를 구하기 힘듦
  - 얼랭은 고도로 분산된 병렬 애플리케이션을 위해 고안된 프로그래밍 언어이자 런타임 환경임
  - 얼랭의 강력함은 경량 프로세스임
    - 얼랭 프로세스는 BEAM VM에서 실행되는 개체(entity)임
    - 프로세스 생성 비용이 리눅스 프로세스 생성에 비해 엄청 저렴함
    - 가장 작은 프로세스는 300바이트의 메모리만 사용함
    - 최신 서버 한 대로 수백만 프로세스를 실행 가능함
    - 아무 작업도 하지 않는 프로세스는 CPU 자원을 전혀 소모하지 않음
  - 얼랭을 사용해 웹소켓 서비스를 구현하고, 레디스 펍/섭 서버에서 각 사용자는 얼랭 프로세스 하나로 대체 가능
  - 얼랭/OTP는 구독 기능을 내장하고 있어서 레디스 펍/섭 서버를 대체할 수 있음

## 4단계 - 마무리
- 핵심 컴포넌트
  - 웹 소켓
    - 클라이언트와 서버 사이의 실시간 통신
  - 레디스
    - 위치 데이터의 빠른 읽기/쓰기 지원
  - 레디스 펍/섭
    - 한 사용자의 위치 정보 변경 내역을 모든 온라인 친구에게 전달하는 라우팅 계층
---
# 3장 - 구글 맵
## 1단계 - 문제 이해 및 설계 범위 확정

## 2단계 - 개략적 설계안 제시 및 동의 구하기

## 3단계 - 상세 설계

## 4단계 - 마무리